{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from datetime import datetime, date\n",
    "from nltk import FreqDist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from stop_words import get_stop_words\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "os.chdir(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from src.modeling import BERTopic_\n",
    "from src.config import (\n",
    "    umap_data,\n",
    "    hdbscan_data,\n",
    "    sent_transformers_data,\n",
    "    tfidf_data,\n",
    "    tokenizer_data,\n",
    "    mmr_data,\n",
    "    bertopic_data,\n",
    ")\n",
    "from src.data_preprocess import Preprocessing\n",
    "from src.utils import (\n",
    "    getClusteringModel,\n",
    "    getDimReductionModel,\n",
    "    getMaximalMarginalRelevance,\n",
    "    getTfidfTransformers,\n",
    "    getTokenizer,\n",
    "    getEmbeddings,\n",
    "    getFrequencyDictForText,\n",
    "    plot_wordcloud,\n",
    "    global_wordcloud,\n",
    "    context_stopwords\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/context-sw.txt') as f:\n",
    "    list_context_sw = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "language = \"french\"\n",
    "spacy_model = 'fr_core_news_md'\n",
    "transformer = \"dangvantuan/sentence-camembert-large\"\n",
    "preprocessor = Preprocessing(spacy_model, language, list_context_sw)\n",
    "\n",
    "docs_name = \"chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for token in sorted(list_context_sw):\n",
    "#     print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path =  \"./data/chatbot_data_file.csv\"\n",
    "\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    df_docs = pd.read_csv(f, sep=\"|\", encoding=\"utf-8\")\n",
    "\n",
    "df_docs[\"date_day\"] = df_docs[\"date\"].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\").strftime(\"%A\"))\n",
    "df_docs[\"language\"] = df_docs[\"question\"].apply(preprocessor.getLanguage).apply(lambda x: x if x in [\"fr\", \"en\"] else 'other_lang')\n",
    "df_docs[\"length\"] = df_docs[\"question\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang = df_docs[[\"language\", \"question\"]].groupby(\"language\").count().reset_index()\n",
    "df_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df_lang, values='question', names='language', title='Represented languages in docs', width=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_docs, x=\"length\", width=800, height=500, labels={\"length\": \"Question Length\"}, histnorm='probability density')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep docs in language = \"french\" only\n",
    "df_docs[\"clean_question\"] = df_docs[\"question\"].apply(preprocessor.pipeline)\n",
    "df_docs[\"empty_clean_question\"] = df_docs[\"clean_question\"].apply(lambda x: len(x) == 0)\n",
    "df_docs = df_docs.query(\"language == 'fr' and empty_clean_question == False\").reset_index(drop=True)\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs = df_docs[\"question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_docs[\"clean_question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFrequencyDictForText(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_wordcloud(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = getDimReductionModel(umap_data())\n",
    "hdbscan_model = getClusteringModel(hdbscan_data())\n",
    "vectorizer_model = getTokenizer(tokenizer_data(language=language), list_context_sw)\n",
    "ctfidf_model = getTfidfTransformers(tfidf_data())\n",
    "mmr_model = getMaximalMarginalRelevance(mmr_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_config = bertopic_data(\n",
    "    umap_model,\n",
    "    hdbscan_model,\n",
    "    vectorizer_model,\n",
    "    ctfidf_model,\n",
    "    mmr_model,\n",
    "    nr_topics=\"auto\"\n",
    ")\n",
    "\n",
    "bert_topic_inst = BERTopic_(bertopic_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.fit_or_load(transformer, docs_name, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.intertopic_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.reduce_topics_(docs, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.heatmap_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.barchart_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_representative = bert_topic_inst.representative_docs(docs, raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id_ = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_representative.query(f\"topic_id == {topic_id_} and representative_doc == True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.topic_infeence(docs, raw_docs, topic_id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
