{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/.local/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/onyxia/.local/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/onyxia/.local/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/onyxia/.local/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from datetime import datetime, date\n",
    "from nltk import FreqDist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from stop_words import get_stop_words\n",
    "import spacy\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "os.chdir(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from src.modeling import _BERTopic\n",
    "from src.config import (\n",
    "    umap_data,\n",
    "    hdbscan_data,\n",
    "    sent_transformers_data,\n",
    "    tfidf_data,\n",
    "    tokenizer_data,\n",
    "    mmr_data,\n",
    "    bertopic_data,\n",
    ")\n",
    "from src.data_preprocess import Preprocessing\n",
    "from src.utils import (\n",
    "    getClusteringModel,\n",
    "    getDimReductionModel,\n",
    "    getMaximalMarginalRelevance,\n",
    "    getTfidfTransformers,\n",
    "    getTokenizer,\n",
    "    getEmbeddings,\n",
    "    getFrequencyDictForText,\n",
    "    plot_wordcloud,\n",
    "    global_wordcloud,\n",
    "    context_stopwords\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/test-context-stopwords.txt') as f:\n",
    "    list_context_sw = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "language = \"french\"\n",
    "spacy_model = 'fr_core_news_md'\n",
    "transformer = \"dangvantuan/sentence-camembert-large\"\n",
    "use_preprocessing = False\n",
    "preprocessor = Preprocessing(spacy_model, language, list_context_sw, use_preprocessing)\n",
    "\n",
    "docs_name = \"tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path =  \"./data/sample.csv\"\n",
    "\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    df_docs = pd.read_csv(f, sep=\"|\", encoding=\"utf-8\")\n",
    "\n",
    "df_docs[\"date_day\"] = df_docs[\"date\"].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\").strftime(\"%A\"))\n",
    "df_docs[\"language\"] = df_docs[\"question\"].apply(preprocessor.getLanguage).apply(lambda x: x if x in [\"fr\", \"en\"] else 'other_lang')\n",
    "df_docs[\"length\"] = df_docs[\"question\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang = df_docs[[\"language\", \"question\"]].groupby(\"language\").count().reset_index()\n",
    "df_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(\n",
    "    df_lang,\n",
    "    values='question',\n",
    "    names='language',\n",
    "    title='Represented languages in docs',\n",
    "    width=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_docs,\n",
    "    x=\"length\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    labels={\"length\": \"Question Length\"},\n",
    "    histnorm='probability density'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep docs in language = \"french\" only\n",
    "df_docs[\"clean_question\"] = df_docs[\"question\"].apply(preprocessor.pipeline)\n",
    "df_docs[\"empty_clean_question\"] = df_docs[\"clean_question\"].apply(lambda x: len(x) == 0)\n",
    "df_docs = df_docs.query(\"language == 'fr' and empty_clean_question == False\").reset_index(drop=True)\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs = df_docs[\"question\"].tolist()\n",
    "\n",
    "docs = df_docs[\"clean_question\"].tolist()docs = df_docs[\"clean_question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_wordcloud(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
