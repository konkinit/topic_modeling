{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from stop_words import get_stop_words\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "\n",
    "os.chdir(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from src.modeling import BERTopic_\n",
    "from src.config import (\n",
    "    umap_data,\n",
    "    hdbscan_data,\n",
    "    sent_transformers_data,\n",
    "    tfidf_data,\n",
    "    tokenizer_data,\n",
    "    mmr_data,\n",
    "    bertopic_data,\n",
    ")\n",
    "from src.data_preprocess import Preprocessing\n",
    "from src.utils import (\n",
    "    getClusteringModel,\n",
    "    getDimReductionModel,\n",
    "    getMaximalMarginalRelevance,\n",
    "    getTfidfTransformers,\n",
    "    getTokenizer,\n",
    "    getEmbeddings,\n",
    "    getFrequencyDictForText,\n",
    "    create_wordcloud,\n",
    "    global_wordcloud,\n",
    "    context_stopword\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download fr_core_news_md\n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/context-sw.txt') as f:\n",
    "    list_context_sw = [line.strip() for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "language = \"french\"\n",
    "spacy_model = 'fr_core_news_md'\n",
    "transformer = \"dangvantuan/sentence-camembert-large\"\n",
    "preprocessor = Preprocessing(spacy_model, language, list_context_sw)\n",
    "\n",
    "docs_name = \"chatbot-sample\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path =  \"./data/chatbot_data_file_sample.csv\"\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    df_docs = pd.read_csv(f, sep=\"|\", encoding=\"utf-8\")\n",
    "\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs[\"language\"] = df_docs[\"question\"].apply(preprocessor.getLanguage)\n",
    "\n",
    "# df_docs[\"max_length\"] = df_docs[\"question\"].apply(lambda x: max([len(token) for token in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_docs[\"language\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*df_docs[\"language\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep docs in french only\n",
    "df_docs[df_docs[\"language\"] == \"fr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs = df_docs[df_docs[\"language\"] == 'fr'].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_docs[\"question\"].apply(preprocessor.pipeline).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs[\"question\"].apply(preprocessor.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFrequencyDictForText(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_wordcloud(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = getDimReductionModel(umap_data())\n",
    "hdbscan_model = getClusteringModel(hdbscan_data())\n",
    "vectorizer_model = getTokenizer(tokenizer_data(language=language), list_context_sw)\n",
    "ctfidf_model = getTfidfTransformers(tfidf_data())\n",
    "mmr_model = getMaximalMarginalRelevance(mmr_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_config = bertopic_data(\n",
    "    umap_model,\n",
    "    hdbscan_model,\n",
    "    vectorizer_model,\n",
    "    ctfidf_model,\n",
    "    mmr_model,\n",
    "    nr_topics=\"auto\"\n",
    ")\n",
    "\n",
    "bert_topic_inst = BERTopic_(bertopic_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.fit_or_load(transformer, docs_name, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.visual_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wordcloud(bert_topic_inst.model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.tabular_inference(docs)[1][[\"Document\", \"Topic\", \"Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
