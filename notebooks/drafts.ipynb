{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from stop_words import get_stop_words\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "\n",
    "os.chdir(\"../\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from src.modeling import BERTopic_\n",
    "from src.config import (\n",
    "    umap_data,\n",
    "    hdbscan_data,\n",
    "    sent_transformers_data,\n",
    "    tfidf_data,\n",
    "    tokenizer_data,\n",
    "    mmr_data,\n",
    "    bertopic_data,\n",
    ")\n",
    "from src.data_preprocess import Preprocessing\n",
    "from src.utils import (\n",
    "    getClusteringModel,\n",
    "    getDimReductionModel,\n",
    "    getMaximalMarginalRelevance,\n",
    "    getTfidfTransformers,\n",
    "    getTokenizer,\n",
    "    getEmbeddings,\n",
    "    getFrequencyDictForText,\n",
    "    create_wordcloud,\n",
    "    global_wordcloud,\n",
    "    context_stopword\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path =  \"./data/chatbot_data_file_sample.csv\"\n",
    "with open(sample_file_path, 'rb') as f:\n",
    "    df_docs = pd.read_csv(f, sep=\"|\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_context_sw = [\n",
    "    \"ca\",\n",
    "    \"ok\",\n",
    "    \"dj\",\n",
    "    \"quil\",\n",
    "    \"tjrs\",\n",
    "    \"tjr\",\n",
    "    \"aussitt\",\n",
    "    \"bonjour\",\n",
    "    \"bnjr\",\n",
    "    \"bjr\",\n",
    "    \"bsr\",\n",
    "    \"bonsoir\",\n",
    "    \"ner\",\n",
    "    \"jer\",\n",
    "    \"nest\",\n",
    "    \"déjà\",\n",
    "    \"jen\",\n",
    "    \"salam\",\n",
    "    \"bcp\",\n",
    "    \"cordiale\",\n",
    "    \"cordialement\",\n",
    "    \"quelqu\",\n",
    "    \"club\",\n",
    "    \"total\",\n",
    "    \"energie\",\n",
    "    \"énergie\",\n",
    "    \"totalenergie\",\n",
    "    \"question\",\n",
    "    \"jai\",\n",
    "    \"aije\",\n",
    "    \"narrive\",\n",
    "    \"nai\",\n",
    "    \"savoir\",\n",
    "    \"estce\",\n",
    "    \"sontils\",\n",
    "    \",\",\n",
    "    \"essqu\",\n",
    "    \"cava\",\n",
    "    \"cest\",\n",
    "    \"mexpliquer\",\n",
    "    \"expliquer\",\n",
    "    \"devoir\",\n",
    "    \"pouvoir\",\n",
    "    \"valider\",\n",
    "    \"vouloir\",\n",
    "    \"arriver\",\n",
    "    \"offrir\",\n",
    "    \"perdre\",\n",
    "    \"souhaiter\",\n",
    "    \"fonctionner\",\n",
    "    \"faire\",\n",
    "    \"utiliser\",\n",
    "    \"souscrire\",\n",
    "    \"voir\",\n",
    "    \"venir\",\n",
    "    \"reformuler\",\n",
    "    \"recevoir\"\n",
    "]\n",
    "\n",
    "language = \"french\"\n",
    "spacy_model = 'fr_core_news_md'\n",
    "transformer = \"dangvantuan/sentence-camembert-large\"\n",
    "preprocessor = Preprocessing(spacy_model, language, list_context_sw)\n",
    "\n",
    "docs_name = \"chatbot-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_docs[\"question\"].apply(preprocessor.pipeline).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs[\"question\"].apply(preprocessor.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFrequencyDictForText(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_wordcloud(\" \".join(docs), language, list_context_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_ = \"all-MiniLM-L6-v2\"\n",
    "# docs_name = \"fetch-sample\"\n",
    "# language = \"english\"\n",
    "\n",
    "# docs = fetch_20newsgroups(\n",
    "#    subset=\"all\",\n",
    "#    remove=(\"headers\", \"footers\", \"quotes\")\n",
    "#    )[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = getDimReductionModel(umap_data())\n",
    "hdbscan_model = getClusteringModel(hdbscan_data())\n",
    "vectorizer_model = getTokenizer(tokenizer_data(language=language), list_context_sw)\n",
    "ctfidf_model = getTfidfTransformers(tfidf_data())\n",
    "mmr_model = getMaximalMarginalRelevance(mmr_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_config = bertopic_data(\n",
    "    umap_model, hdbscan_model, vectorizer_model, ctfidf_model, mmr_model, nr_topics=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst = BERTopic_(bertopic_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.fit_or_load(transformer, docs_name, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.visual_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wordcloud(bert_topic_inst.model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_inst.tabular_inference(docs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
